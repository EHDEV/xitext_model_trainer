{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainer-nb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1qpOP-SXZPumRc324Yf50x_Uj1kZ5ps__",
      "authorship_tag": "ABX9TyOnedM2iNvx0V48a/TUqpbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EHDEV/xitext_model_trainer/blob/main/trainer_nb-onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpPAPkOtNAh"
      },
      "source": [
        "#### Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WrmYQ9wMIIu",
        "outputId": "21b3c761-e6e4-42ca-f174-a17b52a897d8"
      },
      "source": [
        "!pip install transformers install onnxruntime onnxruntime-tools\n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.6/dist-packages (1.3.4)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: onnxruntime-tools in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnxruntime) (3.12.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.6/dist-packages (from onnxruntime-tools) (7.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from onnxruntime-tools) (5.4.8)\n",
            "Requirement already satisfied: py3nvml in /usr/local/lib/python3.6/dist-packages (from onnxruntime-tools) (0.2.6)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (from onnxruntime-tools) (1.8.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.6/dist-packages (from onnxruntime-tools) (15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnxruntime) (51.1.1)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (from py3nvml->onnxruntime-tools) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->onnxruntime-tools) (3.7.4.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.6/dist-packages (from coloredlogs->onnxruntime-tools) (9.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxIAxvRXCGvS"
      },
      "source": [
        "#### Download repo and set working directory\n",
        "- Get the latest trainer code from github\n",
        "- set working directory then execute code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yaa5wtbtc1g"
      },
      "source": [
        "import os\n",
        "os.environ['TRAINER_HOME'] = '/content/drive/MyDrive/xitext/xitext_model_trainer'\n",
        "trainer_home = os.environ.get('TRAINER_HOME')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CtaeKjzwfF7",
        "outputId": "d05c8a37-d6a1-4a8e-b7d0-3c76284d08ff"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# export TRAINER_HOME=/content/drive/MyDrive/xitext/xitext_model_trainer\n",
        "cd $TRAINER_HOME; git pull\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/EHDEV/xitext_model_trainer\n",
            "   9d02a1c..ad3218e  main       -> origin/main\n",
            "Updating 9d02a1c..ad3218e\n",
            "Fast-forward\n",
            " models.py | 18 \u001b[32m+++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " 1 file changed, 9 insertions(+), 9 deletions(-)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQesRqsIPoN",
        "outputId": "180ca016-23ae-4342-caa6-a771035de7d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd $trainer_home"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/xitext/xitext_model_trainer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEuAiqktnVm"
      },
      "source": [
        "#### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkma7zrith-k",
        "outputId": "a822e00c-2fa5-4e9d-fff7-2cb94a2cf52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import configparser\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())\n",
        "config.read('config.ini')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['config.ini']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoJgsc-LuKxH"
      },
      "source": [
        "default_config = dict(config['DEFAULT'])\n",
        "data_config = dict(config['DATA'])\n",
        "model_config = dict(config['MODEL'])\n",
        "onnx_config = dict(config['ONNX'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UdZTPR7Cdz-"
      },
      "source": [
        "#### Import classes and required functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYVIsscPML1G"
      },
      "source": [
        "from file_config import FileConfig\n",
        "from models import SequenceClassifierModel\n",
        "from convert_optimize_onnx import TorchToONNX\n",
        "from data_preprocess import TextClassifierData, _encode_text_into_tokens\n",
        "from pathlib import Path\n",
        "import torch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXix1WxsCpRa"
      },
      "source": [
        "#### Set data file path and other configurations of the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwjCp5cB0fv2",
        "outputId": "ffaaec27-9069-4eb4-c8c4-f4934bf87336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_config"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'company': 'xitext',\n",
              " 'company_home': '/content/drive/MyDrive/xitext',\n",
              " 'data_pickle_output_path': '/content/drive/MyDrive/xitext/news-topic-classifier/data/pickles',\n",
              " 'delimiter': ',',\n",
              " 'project_home': '/content/drive/MyDrive/xitext/news-topic-classifier',\n",
              " 'project_name': 'news-topic-classifier',\n",
              " 'source_dir': '/content/drive/MyDrive/xitext/news-topic-classifier/data',\n",
              " 'target_col': 'topic',\n",
              " 'text_col': 'text'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wUt1Z0MqYy"
      },
      "source": [
        "fconfig = FileConfig(\n",
        "    path_to_directory=Path(data_config['source_dir']), \n",
        "    target_column=data_config['target_col'],\n",
        "    sequence_column=data_config['text_col'],\n",
        "    delimiter=data_config['delimiter'])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLtVr9nzSSBZ",
        "outputId": "387167a3-d53e-4822-a03b-119c1526b14d"
      },
      "source": [
        "text_clas_data = TextClassifierData(fconfig)\n",
        "train_data, val_data = text_clas_data.preprocess()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:data-preprocessing.log:load data started\n",
            "DEBUG:data-preprocessing.log:dataframe with shape (200853, 2) has been created\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "DEBUG:data-preprocessing.log:sentence column cleaned\n",
            "DEBUG:data-preprocessing.log:Clean_label_column complete\n",
            "DEBUG:data-preprocessing.log:Underrepresented classes have been removed and data condensed\n",
            "DEBUG:data-preprocessing.log:preparing data for training: train/val split and convert to tensor\n",
            "DEBUG:data-preprocessing.log:train test split completed\n",
            "DEBUG:data-preprocessing.log:Tokenizing train and valid data\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "DEBUG:data-preprocessing.log:Encoding input sentences completed\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "DEBUG:data-preprocessing.log:Encoding input sentences completed\n",
            "DEBUG:data-preprocessing.log:Wrapping tensors in dataloader completed\n",
            "DEBUG:data-preprocessing.log:Wrapping tensors in dataloader completed\n",
            "DEBUG:data-preprocessing.log:data preparation for training is complete. 2385 train and 597 validation examples\n",
            "DEBUG:data-preprocessing.log:Data preprocessing complete\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sqrAW7wHdNB"
      },
      "source": [
        "#### Write classes and their indices as a json in model directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTh9J-nISgI4"
      },
      "source": [
        "import json\n",
        "with open(model_config['classes_file_path'], 'w') as cfile:\n",
        "    cfile.write(json.dumps(\n",
        "        { k: v for k,v in enumerate(text_clas_data.classes) }\n",
        "    ))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGpEuZqh8vQL"
      },
      "source": [
        "pickle_path = Path(data_config['data_pickle_output_path'])\n",
        "if not os.path.isdir(pickle_path):\n",
        "  os.makedirs(pickle_path)\n",
        "\n",
        "torch.save(train_data, pickle_path/'train_pickle.pth')\n",
        "torch.save(val_data, pickle_path/'val_pickle.pth')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caH8veZo87E0"
      },
      "source": [
        "train_data = torch.load(pickle_path/'train_pickle.pth')\n",
        "val_data = torch.load(pickle_path/'val_pickle.pth')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5rtCNmxs_E9"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD3uZ1QK9rx5",
        "outputId": "429435d1-7733-4e20-fe76-f6441163f33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_config"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classes_file_path': '/content/drive/MyDrive/xitext/news-topic-classifier/models/classes.json',\n",
              " 'company': 'xitext',\n",
              " 'company_home': '/content/drive/MyDrive/xitext',\n",
              " 'epochs': '1',\n",
              " 'eval_metric': 'accuracy',\n",
              " 'model_filename': 'distilbert-topic-seq-classifier.bin',\n",
              " 'model_group': 'distilbert',\n",
              " 'model_output_dir': '/content/drive/MyDrive/xitext/news-topic-classifier/models',\n",
              " 'optimizer': 'adam',\n",
              " 'project_home': '/content/drive/MyDrive/xitext/news-topic-classifier',\n",
              " 'project_name': 'news-topic-classifier',\n",
              " 'scheduler': 'linear',\n",
              " 'transformers_model_id': 'distilbert-base-uncased'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iUtImdpXzY_"
      },
      "source": [
        "seq_model = SequenceClassifierModel(\n",
        "    this_project_name=model_config['project_name'], \n",
        "    tr_model_id=model_config['transformers_model_id'],\n",
        "    model_group=model_config['model_group'],\n",
        "    optimizer=model_config['optimizer'],\n",
        "    scheduler=model_config['scheduler'],\n",
        "    eval_metric=model_config['eval_metric'],\n",
        "    num_labels=text_clas_data.num_labels,\n",
        "    epochs=int(model_config['epochs']),\n",
        "    train_data=train_data,\n",
        "    val_data=val_data,\n",
        "    output_dir=model_config['model_output_dir']\n",
        ");\n",
        "\n",
        "seq_model.train(save_model=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOzHHBgtEqN"
      },
      "source": [
        "#### ONNX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp7HSF0gX-83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f267523-6f02-436f-a400-e9694d736914"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "torch_model_path = onnx_config['torch_model_path']\n",
        "onnx_model_dir = Path('/content/drive/MyDrive/xitext/xitext_model_trainer/models/news-topic-classifier/onnx/')\n",
        "\n",
        "tt2 = TorchToONNX(\n",
        "    torch_model_path=torch_model_path,\n",
        "    onnx_model_dir=onnx_model_dir,\n",
        "    tokenizer=text_clas_data.tokenizer\n",
        ")\n",
        "tt2.model_type='bert'"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPY0WufZCg7a"
      },
      "source": [
        "tt2.convert_torch_to_onnx()\n",
        "# tt2.model_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyHMSPwwioqy"
      },
      "source": [
        "from scipy.special import softmax\n",
        "def make_predictions(model, encoded_sentence, attention_mask, token_type_id=None):\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        preds = model(\n",
        "                    encoded_sentence,\n",
        "                    attention_mask=attention_mask\n",
        "                ) \n",
        "            # labels are not passed here in validation\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like softmax\n",
        "        \n",
        "        logits = preds[0]\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=1)        \n",
        "        probabilities = probabilities.detach().cpu().numpy()\n",
        "        # Move logits and labels to CPU\n",
        "\n",
        "        np.set_printoptions(suppress=True)\n",
        "\n",
        "    return probabilities[-1].round(4)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muorruW8jJRO",
        "outputId": "e97f9d2e-8803-41e5-b9c9-eeef7e0d61f5"
      },
      "source": [
        "import numpy as np\n",
        "sentence = [\n",
        "\t'The KKK used to run a youth group called the Klu Klux Kiddies. A sobering reminder of how evil shit like this starts at home.']\n",
        "\n",
        "encoded_tensor = _encode_text_into_tokens( sentence, text_clas_data.tokenizer)\n",
        "\n",
        "# print(encoded_tensor.shape, attention_mask_tensor.shape)\n",
        "\n",
        "seq_model.model.eval()\n",
        "seq_model.model.to('cpu')\n",
        "prediction_probabilities = make_predictions(\n",
        "    model=seq_model.model,\n",
        "    encoded_sentence=encoded_tensor['input_ids'], \n",
        "    attention_mask=encoded_tensor['attention_mask']\n",
        ")\n",
        "\n",
        "from collections import OrderedDict\n",
        "top_topics = OrderedDict()\n",
        "classes=text_clas_data.classes\n",
        "for i in prediction_probabilities.argsort()[-10:][::-1]:\n",
        "    top_topics[classes[i]] = prediction_probabilities[i]\n",
        "\n",
        "top_topics"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
            "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "DEBUG:data-preprocessing.log:Encoding input sentences completed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('politics', 0.5881),\n",
              "             ('black voices', 0.1225),\n",
              "             ('queer voices', 0.0474),\n",
              "             ('crime', 0.044),\n",
              "             ('entertainment', 0.0324),\n",
              "             ('comedy', 0.0297),\n",
              "             ('religion', 0.0254),\n",
              "             ('weird news', 0.0213),\n",
              "             ('healthy living', 0.015),\n",
              "             ('impact', 0.0109)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ZbLubDKLZt"
      },
      "source": [
        "onnx_res = tt2.run_inference(sentence, text_clas_data.tokenizer)\n",
        "\n",
        "from collections import OrderedDict\n",
        "probs = {}\n",
        "for i, x in enumerate(onnx_res[0]):\n",
        "  probs[text_clas_data.classes[i]] = round(x, 4) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GigtjvmrhfhZ",
        "outputId": "065b0991-c741-477c-a828-66c4113535eb"
      },
      "source": [
        "sorted(probs.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('politics', 0.6278),\n",
              " ('black voices', 0.0898),\n",
              " ('queer voices', 0.0752),\n",
              " ('crime', 0.0715),\n",
              " ('entertainment', 0.0501),\n",
              " ('comedy', 0.0192),\n",
              " ('religion', 0.0159),\n",
              " ('weird news', 0.0086),\n",
              " ('business', 0.0062),\n",
              " ('impact', 0.005),\n",
              " ('latino voices', 0.0045),\n",
              " ('arts & culture', 0.0031),\n",
              " ('worldpost', 0.0029),\n",
              " ('women', 0.0026),\n",
              " ('healthy living', 0.0019),\n",
              " ('tech', 0.0017),\n",
              " ('media', 0.0016),\n",
              " ('good news', 0.0012),\n",
              " ('green', 0.001),\n",
              " ('taste', 0.001),\n",
              " ('college', 0.0009),\n",
              " ('food & drink', 0.0009),\n",
              " ('travel', 0.0009),\n",
              " ('arts', 0.0008),\n",
              " ('sports', 0.0008),\n",
              " ('wellness', 0.0008),\n",
              " ('world news', 0.0006),\n",
              " ('parenting', 0.0004),\n",
              " ('the worldpost', 0.0004),\n",
              " ('culture & arts', 0.0003),\n",
              " ('divorce', 0.0003),\n",
              " ('environment', 0.0003),\n",
              " ('fifty', 0.0003),\n",
              " ('parents', 0.0003),\n",
              " ('science', 0.0003),\n",
              " ('education', 0.0002),\n",
              " ('home & living', 0.0002),\n",
              " ('money', 0.0002),\n",
              " ('style', 1e-04),\n",
              " ('style & beauty', 1e-04),\n",
              " ('weddings', 1e-04)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqsKbgaJjdGj"
      },
      "source": [
        "??text_clas_data.data_df['topic'].value_counts().plot(kind='bar', size=(10,12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmLP5vUTm1-T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}